# Where do we get all the stimuli, information about linguistic variables, etc.?

Designing an experiment _might_ be the easy part of the task. Things (in my opinion) get more complicated when you start working on its implementation: What verbs should I use? Where do I get the images? Where do people get their stimuli?

Thankfully, there are a lot of databases and resources availabe online - and lots of folks that have put them all together! Here are a few:

- Dr. Aine Ito's website has a page dedicated to resources, from databases to tutorials. You can find it [here](https://aineito.github.io/resources.html).

This list is divided into linguistic stimuli (for all psycholinguistics experiments), visual stimuli (for those using the Visual World Paradigm), and recommendations for audio editing software (again, Visual World Paradigm folks).

For linguistic stimuli

1. Dr. Jamie Reilly has an extensive list of resources on his lab's website, which you can find [here](https://www.reilly-coglab.com/data). It includes ratings (e.g., Age of Acquisition [AoA], frequency) of words in several languages, amongst other resources. You can make use of these resources to ensure that your linguistic stimuli (be it written or spoken) are matched except for your variables of interest. Dr. Reilly also links to other websites (e.g., [Dr. Dan Mirman's lab](https://www.danmirman.org/research-resources), which expands on his list and includes other resources).

2. A very commonly employed database is the [subtlex database](https://www.ugent.be/pp/experimentele-psychologie/en/research/documents) (scroll to the end of the page), which happens to be UGent-made. It contains word frequencies based on subtitles of films and television, and is available in US English, Chinese, and Dutch.

3. Another common database is the [CELEX database](https://catalog.ldc.upenn.edu/LDC96L14). It contains word frequencies and other values for UK English, Dutch, and German.

Whichever you end up using, you need to properly cite it.

There is always the possibility to obtain your own ratings (e.g., if you are interested in semantic prediction, you will most likely run a cloze task for your materials).

For visual stimuli (images)

The most common database of images in black and white (which also includes ratings of name agreement and visual complexity amongst other important factors to control for) is that Snodgrass and Vanderwart (1980). However, this database is copyright-protected. You can find a list of alternative suggestions [here](https://www.cogsci.nl/stimulus-sets). For example, [Szekely et al., (2004)](https://crl.ucsd.edu/experiments/ipnp/1stimuli.html) have a very nice database of S&V-like images.

Remember to cite the source you end up using in your project! Alternatively, there are a couple of image databases with ratings in our department (see [here](https://www.ugent.be/pp/experimentele-psychologie/en/research/documents)), but they are mostly relevant if your experiment is in Dutch.

For auditory stimuli

Auditory stimuli tend to be experiment-specific (unless you are directly replicating an existing study or you are conducting an observational study). Therefore, there are no databases per se. 

To edit your auditory stimuli (e.g., normalise volume, cross-splice elements) you can use the free software [Audacity](https://www.audacityteam.org/) or [Praat](https://www.fon.hum.uva.nl/praat/). For most purposes, Audacity is enough (and is fairly intuitive to use), but work with the one you feel comfortable with. Again, remember to cite the software that you used in your methods.